{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\umair\\\\Desktop\\\\ML\\\\waterQualityPrediction\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from waterQualityPrediction.constants import *\n",
    "from waterQualityPrediction.utils import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "          \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:   \n",
    "        config = self.config.data_preprocess \n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path\n",
    "        )\n",
    "\n",
    "        return data_transformation_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umair\\AppData\\Local\\Temp\\ipykernel_12548\\3814393511.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import pandas as pd\n",
    "from waterQualityPrediction import logger\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        data = pd.read_csv(self.config.data_path)\n",
    "        logger.info(\"Imputing missing values in the dataset\")\n",
    "        data['ph'] = data.groupby(['Potability'])['ph'].transform('mean')\n",
    "        data['Sulfate'] = data.groupby(['Potability'])['Sulfate'].transform('mean')\n",
    "        data['Trihalomethanes'] = data.groupby(['Potability'])['Trihalomethanes'].transform('mean')\n",
    "        # Removing rows where \"ph\" is less than or equal to 0\n",
    "        logger.info(\"Removing row contain 0\")\n",
    "        data = data[data[\"ph\"] > 0]\n",
    "        \n",
    "        # Applying Box-Cox transformation to all columns\n",
    "        logger.info(\"Normalizing the data with Box-Cox\")\n",
    "        data[\"ph\"], fitted_lambda = scipy.stats.boxcox(data[\"ph\"])\n",
    "        data[\"Hardness\"], fitted_lambda = scipy.stats.boxcox(data[\"Hardness\"])\n",
    "        data[\"Solids\"], fitted_lambda = scipy.stats.boxcox(data[\"Solids\"])\n",
    "        data[\"Chloramines\"], fitted_lambda = scipy.stats.boxcox(data[\"Chloramines\"])\n",
    "        data[\"Sulfate\"], fitted_lambda = scipy.stats.boxcox(data[\"Sulfate\"])\n",
    "        data[\"Conductivity\"], fitted_lambda = scipy.stats.boxcox(data[\"Conductivity\"])\n",
    "        data[\"Organic_carbon\"], fitted_lambda = scipy.stats.boxcox(data[\"Organic_carbon\"])\n",
    "        data[\"Trihalomethanes\"], fitted_lambda = scipy.stats.boxcox(data[\"Trihalomethanes\"])\n",
    "        data[\"Turbidity\"], fitted_lambda = scipy.stats.boxcox(data[\"Turbidity\"])\n",
    "        \n",
    "        #saving data after preprocessing\n",
    "        data.to_csv(os.path.join(self.config.root_dir, \"water-quality-processed.csv\"), index=False)\n",
    "\n",
    "\n",
    "    def train_test_spliting(self):\n",
    "        # data = pd.read_csv(self.config.root_dir)\n",
    "        data = pd.read_csv(os.path.join(self.config.root_dir, \"water-quality-processed.csv\"))\n",
    "\n",
    "        # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "        train, test = train_test_split(data)\n",
    "\n",
    "        train.to_csv(os.path.join(self.config.root_dir, \"train.csv\"),index = False)\n",
    "        test.to_csv(os.path.join(self.config.root_dir, \"test.csv\"),index = False)\n",
    "\n",
    "        logger.info(\"Splited data into training and test sets\")\n",
    "        logger.info(train.shape)\n",
    "        logger.info(test.shape)\n",
    "\n",
    "        print(train.shape)\n",
    "        print(test.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-25 21:25:13,942: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-01-25 21:25:13,945: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-01-25 21:25:13,947: INFO: common: created directory at: artifacts]\n",
      "[2024-01-25 21:25:13,950: INFO: common: created directory at: artifacts/preprocess]\n",
      "[2024-01-25 21:25:13,968: INFO: 901800738: Imputing missing values in the dataset]\n",
      "[2024-01-25 21:25:13,980: INFO: 901800738: Removing row contain 0]\n",
      "[2024-01-25 21:25:13,984: INFO: 901800738: Normalizing the data with Box-Cox]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\umair\\miniconda3\\envs\\water\\lib\\site-packages\\scipy\\stats\\_morestats.py:1121: UserWarning: The optimal lambda is 829.5925732760456, but the returned lambda is theconstrained optimum to ensure that the maximum or the minimum of the transformed data does not cause overflow in float64.\n",
      "  lmax = boxcox_normmax(x, method='mle', optimizer=optimizer)\n",
      "c:\\Users\\umair\\miniconda3\\envs\\water\\lib\\site-packages\\scipy\\stats\\_morestats.py:1121: UserWarning: The optimal lambda is 226.9189068301042, but the returned lambda is theconstrained optimum to ensure that the maximum or the minimum of the transformed data does not cause overflow in float64.\n",
      "  lmax = boxcox_normmax(x, method='mle', optimizer=optimizer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-25 21:25:14,546: INFO: 901800738: Splited data into training and test sets]\n",
      "[2024-01-25 21:25:14,548: INFO: 901800738: (2457, 10)]\n",
      "[2024-01-25 21:25:14,551: INFO: 901800738: (819, 10)]\n",
      "(2457, 10)\n",
      "(819, 10)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.preprocess_data()\n",
    "    data_transformation.train_test_spliting()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "water",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
